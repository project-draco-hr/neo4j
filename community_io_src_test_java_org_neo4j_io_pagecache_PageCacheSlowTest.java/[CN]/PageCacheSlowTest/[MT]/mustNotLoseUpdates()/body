{
  final AtomicBoolean shouldStop=new AtomicBoolean();
  final int cachePages=20;
  final int filePages=cachePages * 2;
  final int threadCount=8;
  final int pageSize=threadCount * 4;
  getPageCache(fs,cachePages,pageSize,PageCacheTracer.NULL);
  final PagedFile pagedFile=pageCache.map(file("a"),pageSize);
  ensureAllPagesExists(filePages,pagedFile);
  List<Future<UpdateResult>> futures=new ArrayList<>();
  for (int i=0; i < threadCount; i++) {
    UpdateWorker worker=new UpdateWorker(i,filePages,shouldStop,pagedFile){
      protected void performReadOrUpdate(      ThreadLocalRandom rng,      boolean updateCounter,      int pf_flags) throws IOException {
        int pageId=rng.nextInt(0,filePages);
        try (PageCursor cursor=pagedFile.io(pageId,pf_flags)){
          int counter;
          try {
            assertTrue(cursor.next());
            do {
              cursor.setOffset(offset);
              counter=cursor.getInt();
            }
 while (cursor.shouldRetry());
            String lockName=updateCounter ? "PF_SHARED_WRITE_LOCK" : "PF_SHARED_READ_LOCK";
            String reason=String.format("inconsistent page read from filePageId = %s, with %s, workerId = %s [t:%s]",pageId,lockName,threadId,Thread.currentThread().getId());
            assertThat(reason,counter,is(pageCounts[pageId]));
          }
 catch (          Throwable throwable) {
            shouldStop.set(true);
            throw throwable;
          }
          if (updateCounter) {
            counter++;
            pageCounts[pageId]++;
            cursor.setOffset(offset);
            cursor.putInt(counter);
          }
        }
       }
    }
;
    futures.add(executor.submit(worker));
  }
  Thread.sleep(40);
  shouldStop.set(true);
  verifyUpdateResults(filePages,pagedFile,futures);
  pagedFile.close();
}
